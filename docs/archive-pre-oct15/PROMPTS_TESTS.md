# üß™ Prompts de Test - Workflows LangChain

**Date** : 11 octobre 2025
**Objectif** : Re-g√©n√©rer les 4 workflows cass√©s avec les nouveaux prompts

---

## üìù COMMENT TESTER

### M√©thode 1 : Via curl

```bash
curl -X POST http://localhost:3002/api/generate \
  -H "Content-Type: application/json" \
  -d '{"request": "VOTRE_PROMPT_ICI"}' \
  -o /tmp/test-result.json
```

### M√©thode 2 : Via l'interface web (si disponible)

Copier-coller les prompts dans l'interface de g√©n√©ration.

---

## ü§ñ TEST 1 - Chatbot Telegram avec M√©moire

### Prompt

```
Cr√©er un chatbot Telegram simple avec m√©moire conversationnelle.

Le bot doit :
- Recevoir les messages des utilisateurs via un webhook Telegram
- Utiliser GPT-4 pour g√©n√©rer des r√©ponses contextuelles
- Stocker l'historique des conversations dans une m√©moire buffer
- R√©pondre aux messages avec le contexte des √©changes pr√©c√©dents

Le workflow doit inclure :
- Un trigger Telegram pour recevoir les messages
- Un AI Agent pour orchestrer la conversation
- Un mod√®le OpenAI (GPT-4) pour g√©n√©rer les r√©ponses
- Une m√©moire buffer pour maintenir le contexte
- Une r√©ponse vers Telegram
```

### Fichier de sortie

```bash
/tmp/test1-chatbot-telegram.json
```

---

## üîç TEST 2 - RAG avec Qdrant (Retrieval Augmented Generation)

### Prompt

```
Cr√©er un syst√®me RAG (Retrieval Augmented Generation) pour r√©pondre aux questions des utilisateurs en se basant sur une base documentaire.

Le syst√®me doit :
- Recevoir une question utilisateur via webhook
- Rechercher dans une base vectorielle Qdrant les documents pertinents
- Utiliser GPT-4 pour g√©n√©rer une r√©ponse enrichie du contexte trouv√©
- Retourner la r√©ponse avec les sources

Le workflow doit inclure :
- Un webhook pour recevoir la question
- Un AI Agent pour orchestrer le RAG
- Un vector store Qdrant pour la recherche s√©mantique
- Des embeddings OpenAI pour vectoriser la question
- Un mod√®le OpenAI (GPT-4) pour la g√©n√©ration
- Une m√©moire pour maintenir le contexte de la conversation
- Une r√©ponse structur√©e avec les sources
```

### Fichier de sortie

```bash
/tmp/test2-rag-qdrant.json
```

---

## üìã TEST 3 - RGPD Information Extractor

### Prompt

```
Cr√©er un extracteur d'informations RGPD pour analyser automatiquement les demandes clients et extraire les donn√©es personnelles mentionn√©es.

Le syst√®me doit :
- Recevoir un email ou message contenant une demande client
- Extraire automatiquement les informations RGPD (nom, email, t√©l√©phone, adresse, etc.)
- Classifier le type de demande (acc√®s, rectification, suppression, etc.)
- Structurer les donn√©es extraites dans un format JSON
- Enregistrer dans une base de donn√©es ou envoyer vers un CRM

Le workflow doit inclure :
- Un trigger (webhook ou email)
- Un Information Extractor LangChain pour extraire les donn√©es
- Un Text Classifier LangChain pour classifier la demande
- Un mod√®le OpenAI (GPT-4) pour l'analyse
- Un node pour structurer et stocker les r√©sultats
```

### Fichier de sortie

```bash
/tmp/test3-rgpd-extractor.json
```

---

## üì∞ TEST 4 - Blog Content Ingestion & Summarization

### Prompt

```
Cr√©er un syst√®me d'ingestion et de r√©sum√© automatique d'articles de blog pour alimenter une newsletter.

Le syst√®me doit :
- R√©cup√©rer r√©guli√®rement de nouveaux articles depuis un flux RSS ou une API
- Extraire le contenu texte de chaque article
- G√©n√©rer un r√©sum√© concis avec GPT-4
- Classifier le contenu par th√©matique (tech, business, etc.)
- Stocker les r√©sum√©s dans une base vectorielle Qdrant pour recherche future
- Envoyer un email avec les meilleurs articles de la semaine

Le workflow doit inclure :
- Un trigger schedule (cron) ou webhook
- Un node pour r√©cup√©rer les articles (HTTP Request ou RSS)
- Un AI Agent pour orchestrer le traitement
- Un Summarization Chain pour r√©sumer les articles
- Un Text Classifier pour classifier par th√©matique
- Un vector store Qdrant pour indexer les r√©sum√©s
- Un mod√®le OpenAI (GPT-4)
- Une m√©moire pour le contexte
- Un node Email pour envoyer la newsletter
```

### Fichier de sortie

```bash
/tmp/test4-blog-ingestion.json
```

---

## ‚úÖ VALIDATION

### Checklist pour chaque workflow g√©n√©r√©

Pour valider qu'un workflow est correct, v√©rifier :

#### 1. Sub-nodes ont parameters vides
```bash
jq '.workflow.nodes[] | select(.type | contains("langchain")) | {name: .name, type: .type, parameters: .parameters}' test.json
```

**Attendu** : Tous les sub-nodes doivent avoir `"parameters": {}`

#### 2. Root node existe
```bash
jq '.workflow.nodes[] | select(.type | contains("agent") or contains("chain"))' test.json
```

**Attendu** : Au moins un root node (agent ou chain)

#### 3. Connexions sp√©ciales pr√©sentes
```bash
jq '.workflow.connections' test.json | grep -E "(ai_languageModel|ai_memory|ai_vectorStore|ai_embedding)"
```

**Attendu** : Connexions avec types `ai_*` vers le root node

#### 4. Pas de connexions "main" entre sub-nodes
```bash
jq '.workflow.connections | to_entries[] | select(.key | contains("OpenAI") or contains("Memory") or contains("Qdrant")) | .value' test.json
```

**Attendu** : Sub-nodes ne doivent PAS avoir de connexions "main" entre eux

---

## üî¨ SCRIPT DE TEST AUTOMATIQUE

```bash
#!/bin/bash

# Script pour tester les 4 workflows

PROMPTS=(
  "Cr√©er un chatbot Telegram simple avec m√©moire conversationnelle..."
  "Cr√©er un syst√®me RAG (Retrieval Augmented Generation)..."
  "Cr√©er un extracteur d'informations RGPD..."
  "Cr√©er un syst√®me d'ingestion et de r√©sum√© automatique d'articles de blog..."
)

OUTPUTS=(
  "/tmp/test1-chatbot-telegram.json"
  "/tmp/test2-rag-qdrant.json"
  "/tmp/test3-rgpd-extractor.json"
  "/tmp/test4-blog-ingestion.json"
)

for i in "${!PROMPTS[@]}"; do
  echo "üß™ Test $((i+1))/4 - ${OUTPUTS[$i]}"

  curl -X POST http://localhost:3002/api/generate \
    -H "Content-Type: application/json" \
    -d "{\"request\": \"${PROMPTS[$i]}\"}" \
    -o "${OUTPUTS[$i]}"

  # Validation basique
  if jq -e '.workflow' "${OUTPUTS[$i]}" > /dev/null 2>&1; then
    echo "‚úÖ Workflow g√©n√©r√©"

    # V√©rifier sub-nodes
    SUBNODE_ERRORS=$(jq '[.workflow.nodes[] | select(.type | contains("langchain")) | select(.type | contains("agent") | not) | select(.type | contains("chain") | not) | select(.parameters != {})] | length' "${OUTPUTS[$i]}")

    if [ "$SUBNODE_ERRORS" -eq 0 ]; then
      echo "‚úÖ Sub-nodes parameters corrects"
    else
      echo "‚ùå $SUBNODE_ERRORS sub-nodes avec parameters incorrects"
    fi
  else
    echo "‚ùå Erreur de g√©n√©ration"
  fi

  echo ""
  sleep 5
done

echo "‚úÖ Tests termin√©s"
```

---

## üìä R√âSULTATS ATTENDUS

| Workflow | Sub-nodes | Root node | Connexions ai_* | Status |
|----------|-----------|-----------|-----------------|--------|
| Chatbot Telegram | 2-3 | AI Agent | ‚úÖ | √Ä tester |
| RAG Qdrant | 4-5 | AI Agent | ‚úÖ | √Ä tester |
| RGPD Extractor | 2-3 | Information Extractor | ‚úÖ | √Ä tester |
| Blog Ingestion | 4-6 | Summarization Chain | ‚úÖ | √Ä tester |

---

## üöÄ APR√àS LES TESTS

### Import dans N8N

```bash
# Pour chaque workflow qui passe la validation
jq '.workflow | .active = false | .name = (.name + " (Test)")' test.json | \
  docker exec -i n8n-subpath-n8n-1 n8n import:workflow --input=-
```

### V√©rification visuelle

1. Ouvrir N8N : https://n8n.synoptia.fr
2. V√©rifier que les nodes s'affichent correctement (pas de "?")
3. V√©rifier les connexions entre nodes
4. Configurer les credentials (OpenAI, Telegram, etc.)
5. Tester l'ex√©cution

---

**Date de cr√©ation** : 11 octobre 2025
**Derni√®re mise √† jour** : 11 octobre 2025 14h00
