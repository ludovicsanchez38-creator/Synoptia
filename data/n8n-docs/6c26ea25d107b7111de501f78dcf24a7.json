{
  "title": "Hosting n8n on Google Cloud",
  "url": "https://docs.n8n.io/hosting/installation/server-setups/google-cloud",
  "content": "---\ncontentType: tutorial\n---\n\n Hosting n8n on Google Cloud\n\nThis hosting guide shows you how to self-host n8n on Google Cloud (GCP). It uses n8n with Postgres as a database backend using Kubernetes to manage the necessary resources and reverse proxy.\n\n Prerequisites\n\n- The gcloud command line tool\n- The gke-gcloud-auth-plugin (install the gcloud CLI first)\n\n--8<-- \"snippets/self-hosting/warning.md\"\n\n--8<-- \"snippets/self-hosting/installation/latest-next-version.md\"\n\n Hosting options\n\nGoogle Cloud offers several options suitable for hosting n8n, including Cloud Run (optimized for running containers), Compute Engine (VMs), and Kubernetes Engine (containers running with Kubernetes).\n\nThis guide uses the Google Kubernetes Engine (GKE) as the hosting option. Using Kubernetes requires some additional complexity and configuration, but is the best method for scaling n8n as demand changes.\n\nMost of the steps in this guide use the Google Cloud UI, but you can also use the gcloud command line tool instead to undertake all the steps.\n\n Create project\n\nGCP encourages you to create projects to logically organize resources and configuration. Create a new project for your n8n deployment from your Google Cloud Console: select the project dropdown menu and then the NEW PROJECT button. Then select the newly created project. As you follow the other steps in this guide, make sure you have the correct project selected.\n\n Enable the Kubernetes Engine API\n\nGKE isn't enabled by default. Search for \"Kubernetes\" in the top search bar and select \"Kubernetes Engine\" from the results.\n\nSelect ENABLE to enable the Kubernetes Engine API for this project.\n\n Create a cluster\n\nFrom the GKE service page, select Clusters > CREATE. Make sure you select the \"Standard\" cluster option, n8n doesn't work with an \"Autopilot\" cluster. You can leave the cluster configuration on defaults unless there's anything specifically you need to change, such as location.\n\n Set Kubectl context\n\nThe rest of the steps in this guide require you to set the GCP instance as the Kubectl context. You can find the connection details for a cluster instance by opening its details page and selecting CONNECT. The displayed code snippet shows a connection string for the gcloud CLI tool. Paste and run the code snippet in the gcloud CLI to change your local Kubernetes settings to use the new gcloud cluster.\n\n Clone configuration repository\n\nKubernetes and n8n require a series of configuration files. You can clone these from this repository locally. The following steps explain the file configuration and how to add your information.\n\nClone the repository with the following command:\n\nAnd change directory:\n\n Configure Postgres\n\nFor larger scale n8n deployments, Postgres provides a more robust database backend than SQLite.\n\n Create a volume for persistent storage\n\nTo maintain data between pod restarts, the Postgres deployment needs a persistent volume. Running Postgres on GCP requires a specific Kubernetes Storage Class. You can read this guide for specifics, but the storage.yaml manifest creates it for you. You may want to change the regions to create the storage in under the allowedTopologies > matchedLabelExpressions > values key. By default, they're set to us-central.\n\n Postgres environment variables\n\nPostgres needs some environment variables set to pass to the application running in the containers.\n\nThe example postgres-secret.yaml file contains placeholders you need to replace with your own values. Postgres will use these details when creating the database..\n\nThe postgres-deployment.yaml manifest then uses the values from this manifest file to send to the application pods.\n\n Configure n8n\n\n Create a volume for file storage\n\nWhile not essential for running n8n, using persistent volumes is required for:\n\n Using nodes that interact with files, such as the binary data node.\n If you want to persist manual n8n encryption keys between restarts. This saves a file containing the key into file storage during startup.\n\nThe n8n-claim0-persistentvolumeclaim.yaml manifest creates this, and the n8n Deployment mounts that claim in the volumes section of the n8n-deployment.yaml manifest.\n\n Pod resources\n\nKubernetes lets you optionally specify the minimum resources application containers need and the limits they can run to. The example YAML files cloned above contain the following in the resources section of the n8n-deployment.yaml and postgres-deployment.yaml files:\n\nThis defines a minimum of 250mb per container, a maximum of 500mb, and lets Kubernetes handle CPU. You can change these values to match your own needs. As a guide, here are the resources values for the n8n cloud offerings:\n\n--8<-- \"snippets/self-hosting/installation/suggested-pod-resources.md\"\n\n Optional: Environment variables\n\nYou can configure n8n settings and behaviors using environment variables.\n\nCreate an n8n-secret.yaml file. Refer to Environment variables for n8n environment variables details.\n\n Deployments\n\nThe two deployment manifests (n8n-deployment.yaml and postgres-deployment.yaml) define the n8n and Postgres applications to Kubernetes.\n\nThe manifests define the following:\n\n- Send the environment variables defined to each application pod\n- Define the container image to use\n- Set resource consumption limits with the resources object\n- The volumes defined earlier and volumeMounts to define the path in the container to mount volumes.\n- Scaling and restart policies. The example manifests define one instance of each pod. You should change this to meet your needs.\n\n Services\n\nThe two service manifests (postgres-service.yaml and n8n-service.yaml) expose the services to the outside world using the Kubernetes load balancer using ports 5432 and 5678 respectively.\n\n Send to Kubernetes cluster\n\nSend all the manifests to the cluster with the following command:\n\n/// note | Namespace error\nYou may see an error message about not finding an \"n8n\" namespace as that resources isn't ready yet. You can run the same command again, or apply the namespace manifest first with the following command:\n\n///\n\n Set up DNS\n\nn8n typically operates on a subdomain. Create a DNS record with your provider for the subdomain and point it to the IP address of the n8n service. Find the IP address of the n8n service from the Services & Ingress menu item of the cluster you want to use under the Endpoints column.\n\n/// note | GKE and IP addresses\nRead this GKE tutorial for more details on how reserved IP addresses work with GKE and Kubernetes resources.\n///\n Delete resources\n\nRemove the resources created by the manifests with the following command:\n\n Next steps\n\n--8<-- \"snippets/self-hosting/installation/server-setups-next-steps.md\"",
  "category": "hosting",
  "nodeType": null,
  "keywords": [
    "hosting",
    "google",
    "cloud",
    "kubernetes",
    "this",
    "postgres",
    "yaml",
    "with",
    "resources",
    "create",
    "deployment",
    "cluster"
  ],
  "fetchedAt": "2025-10-07T16:16:00.605Z",
  "hash": "6c26ea25d107b7111de501f78dcf24a7"
}