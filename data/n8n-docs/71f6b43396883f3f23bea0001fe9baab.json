{
  "title": "MCP Server Trigger node",
  "url": "https://docs.n8n.io/integrations/builtin/core-nodes/n8n-nodes-langchain.mcptrigger",
  "content": "---\ntitle: MCP Server Trigger node documentation\ndescription: Learn how to use the MCP Server Trigger node in n8n. Follow technical documentation to integrate the MCP Server Trigger node into your workflows.\ncontentType: [integration, reference]\n---\n\n MCP Server Trigger node\n\nUse the MCP Server Trigger node to allow n8n to act as a Model Context Protocol (MCP) server, making n8n tools and workflows available to MCP clients.\n\n///  note  | Credentials\nYou can find authentication information for this node here.\n///\n\n How the MCP Server Trigger node works\n\nThe MCP Server Trigger node acts as an entry point into n8n for MCP clients. It operates by exposing a URL that MCP clients can interact with to access n8n tools.\n\nUnlike conventional trigger nodes, which respond to events and pass their output to the next connected node, the MCP Server Trigger node only connects to and executes tool nodes. Clients can list the available tools and call individual tools to perform work.\n\nYou can expose n8n workflows to clients by attaching them with the Custom n8n Workflow Tool node.\n\n/// note | Server-Sent Events (SSE) and streamable HTTP support\nThe MCP Server Trigger node supports both Server-Sent Events (SSE), a long-lived transport built on top of HTTP, and streamable HTTP for connections between clients and the server. It currently doesn't support standard input/output (stdio) transport.\n///\n\n Node parameters\n\nUse these parameters to configure your node.\n\n MCP URL\n\nThe MCP Server Trigger node has two MCP URLs: test and production. n8n displays the URLs at the top of the node panel.\n\nSelect Test URL or Production URL to toggle which URL n8n displays.\n\n Test: n8n registers a test MCP URL when you select Listen for Test Event or Execute workflow, if the workflow isn't active. When you call the MCP URL, n8n displays the data in the workflow.\n Production: n8n registers a production MCP URL when you activate the workflow. When using the production URL, n8n doesn't display the data in the workflow. You can still view workflow data for a production execution: select the Executions tab in the workflow, then select the workflow execution you want to view.\n\n Authentication\n\nYou can require authentication for clients connecting to your MCP URL. Choose from these authentication methods:\n\n- Bearer auth\n- Header auth\n\nRefer to the HTTP request credentials for more information on setting up each credential type.\n\n Path\n\nBy default, this field contains a randomly generated MCP URL path, to avoid conflicts with other MCP Server Trigger nodes. \n\nYou can manually specify a URL path, including adding route parameters. For example, you may need to do this if you use n8n to prototype an API and want consistent endpoint URLs.\n\n Templates and examples\n\n<!-- see https://www.notion.so/n8n/Pull-in-templates-for-the-integrations-pages-37c716837b804d30a33b47475f6e3780 -->\n[[ templatesWidget(page.title, 'mcp-server-trigger') ]]\n\n Integrating with Claude Desktop\n\nYou can connect to the MCP Server Trigger node from Claude Desktop by running a gateway to proxy SSE messages to stdio-based servers.\n\nTo do so, add the following to your Claude Desktop configuration:\n\nBe sure to replace the <MCPURL> and <MCPBEARERTOKEN> placeholders with the values from your MCP Server Trigger node parameters and credentials.\n\n Limitations\n\n Configuring the MCP Server Trigger node with webhook replicas\n\nThe MCP Server Trigger node relies on Server-Sent Events (SSE) or streamable HTTP, which require the same server instance to handle persistent connections. This can cause problems when running n8n in queue mode depending on your webhook processor configuration:\n\n If you use queue mode with a single webhook replica, the MCP Server Trigger node works as expected.\n If you run multiple webhook replicas, you need to route all /mcp requests to a single, dedicated webhook replica. Create a separate replica set with one webhook container for MCP requests. Afterward, update your ingress or load balancer configuration to direct all /mcp traffic to that instance.\n\n/// warning | Caution when running with multiple webhook replicas\nIf you run an MCP Server Trigger node with multiple webhook replicas and don't route all /mcp requests to a single, dedicated webhook replica, your SSE and streamable HTTP connections will frequently break or fail to reliably deliver events.\n///\n\n Related resources\n\nn8n also provides an MCP Client Tool node that allows you to connect your n8n AI agents to external tools.\n\nRefer to the MCP documentation and MCP specification for more details about the protocol, servers, and clients.\n\n Common issues\n\nHere are some common errors and issues with the MCP Server Trigger node and steps to resolve or troubleshoot them.\n\n Running the MCP Server Trigger node with a reverse proxy\n\nWhen running n8n behind a reverse proxy like nginx, you may experience problems if the MCP endpoint isn't configured for SSE or streamable HTTP.\n\nSpecifically, you need to disable proxy buffering for the endpoint. Other items you might want to adjust include disabling gzip compression (n8n handles this itself), disabling chunked transfer encoding, and setting the Connection to an empty string to remove it from the forwarded headers. Explicitly disabling these in the MCP endpoint ensures they're not inherited from other places in your nginx configuration.\n\nAn example nginx location block for serving MCP traffic with these settings may look like this:",
  "category": "core-nodes",
  "nodeType": "n8n-nodes-langchain.mcptrigger.md",
  "keywords": [
    "server",
    "trigger",
    "node",
    "with",
    "your",
    "workflow",
    "webhook",
    "clients",
    "http",
    "when"
  ],
  "fetchedAt": "2025-10-07T16:14:14.300Z",
  "hash": "71f6b43396883f3f23bea0001fe9baab"
}