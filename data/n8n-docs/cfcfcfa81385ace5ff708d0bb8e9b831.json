{
  "title": "Hosting n8n on Amazon Web Services",
  "url": "https://docs.n8n.io/hosting/installation/server-setups/aws",
  "content": "---\ncontentType: tutorial\n---\n\n Hosting n8n on Amazon Web Services\n\nThis hosting guide shows you how to self-host n8n with Amazon Web Services (AWS). It uses n8n with Postgres as a database backend using Kubernetes to manage the necessary resources and reverse proxy.\n\n Hosting options\n\nAWS offers several ways suitable for hosting n8n, including EC2 (virtual machines), and EKS (containers running with Kubernetes).\n\nThis guide uses EKS as the hosting option. Using Kubernetes requires some additional complexity and configuration, but is the best method for scaling n8n as demand changes.\n\n Prerequisites\n\nThe steps in this guide use a mix of the AWS UI and the eksctl CLI tool for EKS.\n\nWhile not mentioned in the documentation for eksctl, you also need to install the AWS CLI tool, and configure authentication of the tool.\n\n--8<-- \"snippets/self-hosting/warning.md\"\n\n--8<-- \"snippets/self-hosting/installation/latest-next-version.md\"\n\n Create a cluster\n\nUse the eksctl tool to create a cluster specifying a name and a region with the following command:\n\nThis can take a while to create the cluster.\n\nOnce the cluster is created, eksctl automatically sets the kubectl context to the cluster.\n\n Clone configuration repository\n\nKubernetes and n8n require a series of configuration files. You can clone these from this repository. The following steps tell you what each file does, and what settings you need to change.\n\nClone the repository with the following command:\n\nAnd change directory:\n\n Configure Postgres\n\nFor larger scale n8n deployments, Postgres provides a more robust database backend than SQLite.\n\n Configure volume for persistent storage\n\nTo maintain data between pod restarts, the Postgres deployment needs a persistent volume. The default AWS storage class, gp3, is suitable for this purpose. This is defined in the postgres-claim0-persistentvolumeclaim.yaml manifest.\n\n Postgres environment variables\n\nPostgres needs some environment variables set to pass to the application running in the containers.\n\nThe example postgres-secret.yaml file contains placeholders you need to replace with values of your own for user details and the database to use.\n\nThe postgres-deployment.yaml manifest then uses the values from this manifest file to send to the application pods.\n\n Configure n8n\n\n Create a volume for file storage\n\nWhile not essential for running n8n, using persistent volumes helps maintain files uploaded while using n8n and if you want to persist manual n8n encryption keys between restarts, which saves a file containing the key into file storage during startup.\n\nThe n8n-claim0-persistentvolumeclaim.yaml manifest creates this, and the n8n Deployment mounts that claim in the volumes section of the n8n-deployment.yaml manifest.\n\n Pod resources\n\nKubernetes lets you specify the minimum resources application containers need and the limits they can run to. The example YAML files cloned above contain the following in the resources section of the n8n-deployment.yaml file:\n\nThis defines a minimum of 250mb per container, a maximum of 500mb, and lets Kubernetes handle CPU. You can change these values to match your own needs. As a guide, here are the resources values for the n8n cloud offerings:\n\n--8<-- \"snippets/self-hosting/installation/suggested-pod-resources.md\"\n\n Optional: Environment variables\n\nYou can configure n8n settings and behaviors using environment variables.\n\nCreate an n8n-secret.yaml file. Refer to Environment variables for n8n environment variables details.\n\n Deployments\n\nThe two deployment manifests (n8n-deployment.yaml and postgres-deployment.yaml) define the n8n and Postgres applications to Kubernetes.\n\nThe manifests define the following:\n\n- Send the environment variables defined to each application pod\n- Define the container image to use\n- Set resource consumption limits\n- The volumes defined earlier and volumeMounts to define the path in the container to mount volumes.\n- Scaling and restart policies. The example manifests define one instance of each pod. You should change this to meet your needs.\n\n Services\n\nThe two service manifests (postgres-service.yaml and n8n-service.yaml) expose the services to the outside world using the Kubernetes load balancer using ports 5432 and 5678 respectively by default.\n\n Send to Kubernetes cluster\n\nSend all the manifests to the cluster by running the following command in the n8n-kubernetes-hosting directory:\n\n/// note | Namespace error\nYou may see an error message about not finding an \"n8n\" namespace as that resources isn't ready yet. You can run the same command again, or apply the namespace manifest first with the following command:\n\n///\n\n Set up DNS\n\nn8n typically operates on a subdomain. Create a DNS record with your provider for the subdomain and point it to a static address of the instance.\n\nTo find the address of the n8n service running on the instance:\n\n1. Open the Clusters section of the Amazon Elastic Kubernetes Service page in the AWS console.\n2. Select the name of the cluster to open its configuration page.\n3. Select the Resources tab, then Service and networking > Services.\n4. Select the n8n service and copy the Load balancer URLs value. Use this value suffixed with the n8n service port (5678) for DNS.\n\n/// note | Use HTTP\nThis guide uses HTTP connections for the services it defines, for example in n8n-deployment.yaml. However, if you click the Load balancer URLs value, EKS takes you to an \"HTTPS\" URL which results in an error. To solve this, when you open the n8n subdomain, make sure to use HTTP.\n///\n Delete resources\n\nIf you need to delete the setup, you can remove the resources created by the manifests with the following command:\n\n Next steps\n\n--8<-- \"snippets/self-hosting/installation/server-setups-next-steps.md\"",
  "category": "hosting",
  "nodeType": null,
  "keywords": [
    "hosting",
    "amazon",
    "services",
    "this",
    "yaml",
    "postgres",
    "kubernetes",
    "with",
    "resources",
    "deployment",
    "cluster",
    "following"
  ],
  "fetchedAt": "2025-10-07T16:16:00.050Z",
  "hash": "cfcfcfa81385ace5ff708d0bb8e9b831"
}